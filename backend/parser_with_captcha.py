#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü–∞—Ä—Å–µ—Ä –ê–≤–∏—Ç–æ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–µ—à–µ–Ω–∏—è –∫–∞–ø—á
–ö–∞–ø—á—É —Ä–µ—à–∞–µ—Ç –æ–ø–µ—Ä–∞—Ç–æ—Ä (–ø–æ—Ç–æ–º –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ RuCaptcha)
"""

from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeout
import json
import time
import random
from typing import List, Dict, Optional

class AvitoParserWithCaptcha:
    """–ü–∞—Ä—Å–µ—Ä –ê–≤–∏—Ç–æ —á–µ—Ä–µ–∑ Playwright —Å —Ä–µ—à–µ–Ω–∏–µ–º –∫–∞–ø—á"""
    
    def __init__(self, proxy: str = None, headless: bool = False):
        """
        Args:
            proxy: –ü—Ä–æ–∫—Å–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ http://user:pass@host:port
            headless: False –¥–ª—è VNC –¥–æ—Å—Ç—É–ø–∞ (—á—Ç–æ–±—ã —è –≤–∏–¥–µ–ª –∫–∞–ø—á—É)
        """
        self.proxy = proxy
        self.headless = headless
        self.cookies_file = "/tmp/avito_cookies.json"
        
    def solve_captcha_manually(self, page):
        """
        –ñ–¥—ë—Ç –ø–æ–∫–∞ –æ–ø–µ—Ä–∞—Ç–æ—Ä (—è) —Ä–µ—à—É –∫–∞–ø—á—É –≤—Ä—É—á–Ω—É—é
        –ü–æ—Ç–æ–º –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ RuCaptcha API
        """
        print("üî¥ –ö–ê–ü–ß–ê –û–ë–ù–ê–†–£–ñ–ï–ù–ê!")
        print("–°–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ /tmp/captcha.png")
        
        # –°–∫—Ä–∏–Ω—à–æ—Ç –∫–∞–ø—á–∏
        page.screenshot(path="/tmp/captcha.png")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ webshare –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
        page.screenshot(path="/var/www/tk-kontinental/captcha.png")
        
        print("–û—Ç–∫—Ä–æ–π: http://151.247.209.203/captcha.png")
        print()
        print("–†–µ—à–∞—é –∫–∞–ø—á—É...")
        
        # TODO: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è RuCaptcha API
        # captcha_img = page.query_selector("img[class*='captcha']")
        # –û—Ç–ø—Ä–∞–≤–∏—Ç—å –Ω–∞ RuCaptcha ‚Üí –ø–æ–ª—É—á–∏—Ç—å —Ä–µ—à–µ–Ω–∏–µ ‚Üí –≤–≤–µ—Å—Ç–∏
        
        # –ü–æ–∫–∞ –∂–¥—É —Ä—É—á–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è (30 —Å–µ–∫—É–Ω–¥)
        try:
            page.wait_for_url(lambda url: "captcha" not in url.lower(), timeout=30000)
            print("‚úÖ –ö–∞–ø—á–∞ —Ä–µ—à–µ–Ω–∞!")
            return True
        except:
            print("‚ùå –ö–∞–ø—á–∞ –Ω–µ —Ä–µ—à–µ–Ω–∞ –∑–∞ 30 —Å–µ–∫—É–Ω–¥")
            return False
    
    def load_cookies(self, context):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ cookies"""
        try:
            with open(self.cookies_file, 'r') as f:
                cookies = json.load(f)
                context.add_cookies(cookies)
                print("‚úÖ Cookies –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
                return True
        except:
            print("‚ÑπÔ∏è Cookies –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –Ω–∞—á–∏–Ω–∞–µ–º —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞")
            return False
    
    def save_cookies(self, context):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å cookies –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        cookies = context.cookies()
        with open(self.cookies_file, 'w') as f:
            json.dump(cookies, f)
        print("‚úÖ Cookies —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
    
    def parse_listing(self, city: str, category: str, max_pages: int = 3) -> List[Dict]:
        """
        –ü–∞—Ä—Å–∏—Ç –ª–∏—Å—Ç–∏–Ω–≥ —á–µ—Ä–µ–∑ —Ä–µ–∞–ª—å–Ω—ã–π –±—Ä–∞—É–∑–µ—Ä
        
        Args:
            city: –ì–æ—Ä–æ–¥ (vorkuta)
            category: –ö–∞—Ç–µ–≥–æ—Ä–∏—è (avtomobili)
            max_pages: –°–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω–∏—Ü
            
        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        """
        ads = []
        
        with sync_playwright() as p:
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±—Ä–∞—É–∑–µ—Ä–∞
            browser_args = {
                "headless": self.headless,
                "args": [
                    "--disable-blink-features=AutomationControlled",
                    "--disable-dev-shm-usage"
                ]
            }
            
            if self.proxy:
                browser_args["proxy"] = {"server": self.proxy}
            
            browser = p.chromium.launch(**browser_args)
            context = browser.new_context(
                viewport={"width": 1920, "height": 1080},
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            )
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º cookies –µ—Å–ª–∏ –µ—Å—Ç—å
            self.load_cookies(context)
            
            page = context.new_page()
            
            try:
                for page_num in range(1, max_pages + 1):
                    url = f"https://www.avito.ru/{city}/{category}?p={page_num}"
                    print(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: {url}")
                    
                    page.goto(url, wait_until="domcontentloaded", timeout=30000)
                    
                    # –°–ª—É—á–∞–π–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ (–∏–º–∏—Ç–∞—Ü–∏—è —á–µ–ª–æ–≤–µ–∫–∞)
                    time.sleep(random.uniform(2, 4))
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–∞–ø—á—É
                    if "captcha" in page.url.lower() or page.query_selector("form[class*='captcha']"):
                        if not self.solve_captcha_manually(page):
                            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–µ—à–∏—Ç—å –∫–∞–ø—á—É, –ø—Ä–µ—Ä—ã–≤–∞–µ–º")
                            break
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º cookies –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è
                        self.save_cookies(context)
                        
                        # –ü–æ–≤—Ç–æ—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å
                        page.goto(url, wait_until="domcontentloaded")
                    
                    # –ü–∞—Ä—Å–∏–º –æ–±—ä—è–≤–ª–µ–Ω–∏—è
                    page_ads = self._extract_ads_from_page(page)
                    print(f"  –ù–∞–π–¥–µ–Ω–æ: {len(page_ads)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
                    
                    ads.extend(page_ads)
                    
                    # –°–∫—Ä–æ–ª–ª –≤–Ω–∏–∑ (–∏–º–∏—Ç–∞—Ü–∏—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞)
                    page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                    time.sleep(1)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º cookies –≤ –∫–æ–Ω—Ü–µ
                self.save_cookies(context)
                
            finally:
                browser.close()
        
        return ads
    
    def _extract_ads_from_page(self, page) -> List[Dict]:
        """–ò–∑–≤–ª–µ—á—å –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        ads = []
        
        # –°–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        items = page.query_selector_all("div[data-marker='item']")
        
        for item in items:
            try:
                ad = {}
                
                # ID
                ad['avito_id'] = item.get_attribute('data-item-id') or ''
                
                # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∏ URL
                title_elem = item.query_selector("a[data-marker='item-title']")
                if title_elem:
                    ad['title'] = title_elem.inner_text().strip()
                    href = title_elem.get_attribute('href')
                    ad['url'] = f"https://www.avito.ru{href}" if href.startswith('/') else href
                
                # –¶–µ–Ω–∞
                price_elem = item.query_selector("[data-marker='item-price']")
                if price_elem:
                    price_text = price_elem.inner_text().strip()
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ
                    price_clean = ''.join(filter(str.isdigit, price_text))
                    ad['price'] = int(price_clean) if price_clean else None
                
                # –û–ø–∏—Å–∞–Ω–∏–µ
                desc_elem = item.query_selector("[data-marker='item-description']")
                if desc_elem:
                    ad['description'] = desc_elem.inner_text().strip()
                
                # –ö–∞—Ä—Ç–∏–Ω–∫–∞
                img_elem = item.query_selector("img[data-marker='item-photo']")
                if img_elem:
                    ad['image_url'] = img_elem.get_attribute('src') or img_elem.get_attribute('data-src')
                
                if ad.get('title') and ad.get('url'):
                    ads.append(ad)
                    
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {e}")
                continue
        
        return ads


# –¢–µ—Å—Ç
if __name__ == "__main__":
    parser = AvitoParserWithCaptcha(
        proxy=None,  # –ü–æ–∫–∞ –±–µ–∑ –ø—Ä–æ–∫—Å–∏
        headless=True  # True = –Ω–µ –≤–∏–¥–Ω–æ –±—Ä–∞—É–∑–µ—Ä–∞, False = –≤–∏–¥–Ω–æ
    )
    
    print("=== –¢–ï–°–¢ –ü–ê–†–°–ï–†–ê –° –ö–ê–ü–ß–ê–ú–ò ===")
    print()
    
    ads = parser.parse_listing("vorkuta", "avtomobili", max_pages=1)
    
    print()
    print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ: {len(ads)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
    
    if ads:
        print()
        print("–ü—Ä–∏–º–µ—Ä:")
        ad = ads[0]
        print(f"  –ó–∞–≥–æ–ª–æ–≤–æ–∫: {ad.get('title', '')[:60]}")
        print(f"  –¶–µ–Ω–∞: {ad.get('price')} ‚ÇΩ")
        print(f"  URL: {ad.get('url')}")
